# Jciu<-cisJ[2,]-mean(JxJD)-coef(tempMod)[1] # upper CI bound
Jcil<-inv.logit(cisJ[1,]) # lowerCI bound
Jciu<-inv.logit(cisJ[2,]) # upper CI bound
JplotDF = data.frame(JDayForPlotting,RealFitCenterJ)
colnames(JplotDF) = c("Jday","Fit")
dJday = stats::density(thisSite$JulianDay,na.rm = TRUE,n=256,from=1,to=365) # Calculate kernel density of Jday observations
Jdens = data.frame(c(dJday$x,rev(dJday$x)),c(dJday$y,rep(0,length(dJday$y))))
colnames(Jdens) = c("Day","Density")
Jdens$Density = rescale(Jdens$Density, to=c(0.95*min(Jcil),min(Jcil))) # rescale density to sit at bottom of y-axis
ggplot(JplotDF, aes(Jday, Fit),
# ) + geom_polygon(data=Jdens,
#                  aes(Day,Density),
#                  fill=4,
#                  alpha=0.2
) + geom_smooth(fill = "grey",
colour = "black",
aes(ymin=Jcil, ymax=1.05*Jciu),
stat ="identity"
) + labs(x = "Julian Day",
y = "s(Julian Day)",
#title = paste(CTname, 'at',site),
) + theme(axis.line = element_line(),
panel.background = element_blank()
)
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
dateS[i]
which(dateS[i] >= global_expts$start)
View(global_expts)
which(global_expts$start >= dateS[i])
which(dateE[i] <= global_expts$end)
url
dateSubsetStarts
dateSubsetEnds
dateSubsetStarts[1]
dateSubsetEnds[length(dateSubsetEnds)]
dlSpecs
length(url)
dlSpecs
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
dateSubsetStarts
dateSubsetEnds
length(url)
url[j]
fileName
dateSubsetStarts[j]
sprintf('%s/HYCOM_%s_%.0f_%s_%s_%.0f.nc4',saveDir,
covars[l],vertLayers[vertCoord],dateSubsetStarts[j],dateSubsetEnds[j],j)
fileName = sprintf('%s/HYCOM_%s_%.0f_%s_%s_%.0f.nc4',saveDir,
covars[l],vertLayers[vertCoord],dateSubsetStarts[j],dateSubsetEnds[j],j)
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
url[j]
# Download the data
#download.file(url[j], fileName, quiet=FALSE)
return(sprintf('Downloading %s data from %s',covars[l],url[j]))
return(sprintf('Downloading %s data from %s',covars[l],url[j]))
# Download the data
#download.file(url[j], fileName, quiet=FALSE)
sprintf('Downloading %s data from %s',covars[l],url[j])
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
sprintf('%s/HYCOM_%s_%.0f_%s_%s_%.0f.nc4',saveDir,
covars[l],vertLayers[vertCoord],dateSubsetStarts[j],dateSubsetEnds[j],j)
sprintf('%s/HYCOM_%s_%.0f_%s_%s.nc4',saveDir,
covars[l],vertLayers[vertCoord],dateSubsetStarts[j],dateSubsetEnds[j])
source("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
View(global_expts)
source("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
source("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
vertCoord[m]
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
# Enter covariate(s) of interest
covars = c("water_temp","salinity")
# Enter regions of interest; "global" (1/12degree) OR "GoM" (1/25degree)
region <- c("global")
# Enter date range(s) of interest in pairs of start/end dates
dateS <- as.Date(c('2016-09-20','2017-01-01')) # start date(s)
dateE <- as.Date(c('2017-01-25','2017-02-10')) # end date(s)
# Enter study area boundaries in decimal degree lat/long limits
latS <- c(24) # southern bound(s)
latN <- c(46) # northern bound(s)
lonE <- c(-63) # eastern bound(s); use "-" for west of Prime Meridian
lonW <- c(-82) # western bound(s); use "-" for west of Prime Meridian
# SET AT LEAST ONE OF THESE TO NaN
vertCoord = c(1,20) # Enter vertical layer(s) to grab (e.g. 1 for 0.0m, see depths above) OR
vertStride = NaN # Enter vertical stride (1 for all depth layers, 2 for every other, etc.)
# Directory to save data; be sure to use forward slashes!
saveDir = "I:/DataScrapingCode/Test"
# Action -----------------------------------------
dir.create(file.path(saveDir), recursive = TRUE, showWarnings = FALSE)
setwd(saveDir)
# Base urls and data dates for each experiment; note these dates do not reflect the true start/end
# dates of the experiments, but are adjusted to eradicate temporal overlap between experiments
global_expts = data.frame(
url=c('http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1994',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1995',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1996',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1997',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1998',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1999',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2000',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2001',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2002',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2003',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2004',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2005',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2006',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2007',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2008',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2009',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2010',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2011',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2012',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2013',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_56.3',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_57.2',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_92.8',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_57.7',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_92.9',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_93.0',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_93.0'),
start=c(as.Date('1994-01-01'), as.Date('1995-01-01'), as.Date('1996-01-01'),
as.Date('1997-01-01'), as.Date('1998-01-01'), as.Date('1999-01-01'),
as.Date('2000-01-01'), as.Date('2001-01-01'), as.Date('2002-01-01'),
as.Date('2003-01-01'), as.Date('2004-01-01'), as.Date('2005-01-01'),
as.Date('2006-01-01'), as.Date('2007-01-01'), as.Date('2008-01-01'),
as.Date('2009-01-01'), as.Date('2010-01-01'), as.Date('2011-01-01'),
as.Date('2012-01-01'), as.Date('2013-01-01'), as.Date('2014-01-01'),
as.Date('2014-07-01'), as.Date('2016-10-01'), as.Date('2017-02-01'),
as.Date('2017-06-01'), as.Date('2017-10-01'), as.Date('2018-01-01'),
as.Date('2020-02-19')),
end=c(as.Date('1994-12-31'), as.Date('1995-12-31'), as.Date('1996-12-31'),
as.Date('1997-12-31'), as.Date('1998-12-31'), as.Date('1999-12-31'),
as.Date('2000-12-31'), as.Date('2001-12-31'), as.Date('2002-12-31'),
as.Date('2003-12-31'), as.Date('2004-12-31'), as.Date('2005-12-31'),
as.Date('2006-12-31'), as.Date('2007-12-31'), as.Date('2008-12-31'),
as.Date('2009-12-31'), as.Date('2010-12-31'), as.Date('2011-12-31'),
as.Date('2012-12-31'), as.Date('2013-12-31'), as.Date('2014-06-30'),
as.Date('2016-09-30'), as.Date('2017-01-31'), as.Date('2017-05-31'),
as.Date('2017-09-30'), as.Date('2017-12-31'), as.Date('2020-02-18'),
Sys.Date() - 2))
gom_expts = data.frame(
url=c('http://ncss.hycom.org/thredds/ncss/GOMu0.04/expt_50.1',
'http://ncss.hycom.org/thredds/ncss/GOMl0.04/expt_31.0',
'http://ncss.hycom.org/thredds/ncss/GOMl0.04/expt_32.5',
'http://ncss.hycom.org/thredds/ncss/GOMu0.04/expt_90.1m000'),
start=c(as.Date('1993-01-01'), as.Date('2013-01-01'), as.Date('2014-09-01'), as.Date('2019-01-01')),
end=c(as.Date('2012-12-31'), as.Date('2014-08-30'), as.Date('2018-12-31'), as.Date('2021-07-15')))
vertLayers = c(0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 15.0, 20.0, 25.0, 30.0,
35.0, 40.0, 45.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0, 125.0, 150.0, 200.0, 250.0, 300.0, 350.0,
400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1250.0, 1500.0, 2000.0, 2500.0, 3000.0, 4000.0, 5000.0)
i=1
k=1
l=1
q <- which(dateS[i] >= global_expts$start)
r <- which(dateE[i] <= global_expts$end)
idxRange <- c(tail(q,1):r[1])
url <- global_expts$url[idxRange]
dateSubsetStarts <- global_expts$start[idxRange] # subset date ranges by experiment
dateSubsetEnds <- global_expts$end[idxRange]
dateSubsetStarts[1] <- dateS[i]
dateSubsetEnds[length(dateSubsetEnds)] <- dateE[i]
# Construct string containing relevant info on vars, region, period, etc.
dlSpecs <- '?'
# Add the variable
dlSpecs = sprintf('%svar=%s&', dlSpecs, covars[l])
# Add the spatial bounds
dlSpecs = sprintf('%snorth=%.4f&west=%.4f&east=%.4f&south=%.4f&disableProjSubset=on&horizStride=1&',
dlSpecs, latN[k], lonW[k], lonE[k], latS[k] )
!is.na(vertStride)
# Download associated lat-lon points
dlSpecs = sprintf('%saddLatLon=true&', dlSpecs)
# Get data in netcdf4 format
dlSpecs = sprintf('%saccept=netcdf4&', dlSpecs)
j=1
m=1
length(vertCoord)
!is.na(vertCoord)
any(!is.na(vertCoord))
dlSpecs = sprintf('%svertCoord=%s&', dlSpecs, vertCoord[m])
dlSpecs
vertlb = sprintf('vertLayer_%s',vertLayers[m])}
vertlb = sprintf('vertLayer_%s',vertLayers[m])
vertlb
# Add the time range(s) and construct download url(s)
url[j] <- paste(url[j],sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1',
dlSpecs, strftime(dateSubsetStarts[j], '%Y-%m-%dT00'),
strftime(dateSubsetEnds[j], '%Y-%m-%dT00')),sep='')
length(url)>1
fileName = sprintf('%s/HYCOM_%s_%d_%s_%s_%.0f.nc4',saveDir,
covars[l],vertlb,dateSubsetStarts[j],dateSubsetEnds[j],j)
fileName = sprintf('%s/HYCOM_%s_%d_%s_%s_%s.nc4',saveDir,
covars[l],vertlb,dateSubsetStarts[j],dateSubsetEnds[j],j)
covars[l]
vertlb
sprintf('%s/HYCOM_%s_%s_%s_%s_%s.nc4',saveDir,
covars[l],vertlb,dateSubsetStarts[j],dateSubsetEnds[j],j)
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
debugSource("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
source("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
source("D:/Code/MBARC_HabMod/extract_HYCOM_data.R")
library(curl)
library(pracma)
install.packages("ncdf4")
library(ncdf4)
updateR()
source("D:/Code/Temporal_Analyses/Temporal_Models.R")
source("D:/Code/Temporal_Analyses/Temporal_Models.R")
source("D:/Code/Temporal_Analyses/Temporal_Models.R")
library(tidyverse)
library(lubridate)
library(geepack)
library(splines2)
library(SimDesign)
library(pracma)
library(mgcv)
library(car)
library(corrplot)
library(scales)
library(patchwork)
library(boot)
source("getPvalues.r")
modelDFDir = 'I:/TimeSeries_ScaledByEffortError'
outDir = 'I:/ModelOutput'
int = "5minBin"
dfList = list.files(path=modelDFDir,pattern=paste('*Master.csv',sep=""),
full.names=TRUE,recursive=FALSE,
include.dirs=FALSE,no..=TRUE)
dfList
load('I:/TimeSeries_ScaledByEffortError/Kogia_at_WAT_BS_5minBin_Master.csv')
data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Kogia_at_WAT_BS_5minBin_Master.csv'))
thisSite = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Kogia_at_WAT_BS_5minBin_Master.csv'))
View(thisSite)
startInd = which(thisSite$StudyYear>1)
thisSiteTruncated = thisSite[startInd[1],]
thisSiteTruncated = thisSite[startInd,]
View(thisSiteTruncated)
data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD19_at_WAT_GS_5minBin_MasterLun.csv'))
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD19_at_WAT_GS_5minBin_MasterLun.csv'))
View(masterLun)
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
lagID = which(abs(corr$acf)<0.2)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD19_at_WAT_BP_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD26_at_WAT_OC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD26_at_NFC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD26_at_HAT_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/UD19_at_WAT_HZ_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/True_at_WAT_WC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/True_at_WAT_OC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Sperm Whale_at_WAT_BS_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Sperm Whale_at_HAT_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Sperm Whale_at_WAT_BC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Sperm Whale_at_WAT_HZ_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Sowerby_at_WAT_NC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Risso_at_JAX_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Risso_at_HAT_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Risso_at_WAT_NC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Risso_at_WAT_HZ_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
masterLun = data.frame(read.csv('I:/TimeSeries_ScaledByEffortError/Risso_at_WAT_OC_5minBin_MasterLun.csv'))
corr = acf(masterLun$PropPres  ,lag.max=30,na.action=na.exclude,plot=TRUE)
# Determine autocorrelation and create grouping variable for GEEGLMs
corr = acf(masterLun$ProbPres,lag.max=30,na.action=na.exclude,plot=FALSE)
View(masterLun)
# Determine autocorrelation and create grouping variable for GEEGLMs
corr = acf(masterLun$PropPres,lag.max=30,na.action=na.exclude,plot=FALSE)
lagID = which(abs(corr$acf)<0.2) # determine lag at which autocorrelation is <0.2
lagID = which(abs(corr$acf)<0.3) # determine lag at which autocorrelation is <0.2
# Determine autocorrelation and create grouping variable for GEEGLMs
corr = acf(masterLun$PropPres,lag.max=60,na.action=na.exclude,plot=FALSE)
lagID = which(abs(corr$acf)<0.3) # determine lag at which autocorrelation is <0.2
lagID = which(abs(corr$acf)<0.2) # determine lag at which autocorrelation is <0.2
# Determine autocorrelation and create grouping variable for GEEGLM
corr = acf(masterLun$PropPres,lag.max=60,na.action=na.exclude,plot=FALSE)
lagID = which(abs(corr$acf)<0.2) # determine lag at which autocorrelation is <0.2
numClust = length(masterLun$PropPres)/(lagID[1]-1)
if (numClust<length(masterLun$PropPres)){
clustID = rep(1:ceiling(numClust),each=lagID[1])
clustID = clustID[1:numel(masterLun$PropPres)]
} else {
clustID = 1:length(masterLun$PropPres)
}
clustID = rep(1:ceiling(numClust),each=lagID[1])
numClust = ceiling(length(masterLun$PropPres)/(lagID[1]-1))
clustID = rep(1:ceiling(numClust),each=lagID[1])
clustID = rep(1:numClust,each=lagID[1])
# Determine autocorrelation and create grouping variable for GEEGLM
corr = acf(masterLun$PropPres,lag.max=60,na.action=na.exclude,plot=FALSE)
lagID = which(abs(corr$acf)<0.2) # determine lag at which autocorrelation is <0.2
numClust = ceiling(length(masterLun$PropPres)/(lagID[1]-1))
numClust<length(masterLun$PropPres)
clustID = rep(1:numClust,each=lagID[1])
clustID = clustID[1:numel(masterLun$PropPres)]
clustID = clustID[1:length(masterLun$PropPres)]
masterLun$GropuID = clustID
View(masterLun)
View(masterLun)
### Lunar Models
masterLun = data.frame(read.csv(dfList[i]))
lunMod = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1))
+mSpline(PropMoonUp,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1)),
family=poisson,
data=masterLun,
id=GroupID,
corstr="ar1")
library(geepack)
lunMod = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1))
+mSpline(PropMoonUp,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1)),
family=poisson,
data=masterLun,
id=GroupID,
corstr="ar1")
library(tidyverse)
library(lubridate)
library(geepack)
library(splines2)
library(SimDesign)
library(pracma)
library(mgcv)
library(car)
library(corrplot)
library(scales)
library(patchwork)
library(boot)
source("getPvalues.r")
modelDFDir = 'I:/TimeSeries_ScaledByEffortError'
outDir = 'I:/ModelOutput'
int = "5minBin"
dfList = list.files(path=modelDFDir,pattern=paste('*Master.csv',sep=""),
full.names=TRUE,recursive=FALSE,
include.dirs=FALSE,no..=TRUE)
lunMod = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1))
+mSpline(PropMoonUp,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1)),
family=poisson,
data=masterLun,
id=GroupID,
corstr="ar1")
View(masterLun)
masterLun$GroupID = clustID
lunMod = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1))
+mSpline(PropMoonUp,
knots=quantile(AvgLunIllum,probs=c(0.333,0.666)),
Boundary.knots=c(0,1)),
family=poisson,
data=masterLun,
id=GroupID,
corstr="ar1")
View(lunMod)
# Fit GEEGLM:
lunModLin = glm(PropPres~AvgLunIllum+PropMoonUp,
family=poisson,
data=masterLun)
summary(lunModLin)
# Fit GEEGLM:
lunModLin = geeglm(PropPres~AvgLunIllum+PropMoonUp,
family=poisson,
data=masterLun,
id=GroupID,
corstr="ar1")
load('I:/ModelOutput/SmoothFitEval.Rdata')
View(BestJD)
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
hist(masterLun$PropPres)
hist(log(masterLun$PropPres))
hist(ln(masterLun$PropPres))
# Test whether to include Lunar Illuminance as a linear or a smooth term:
mod01 = geeglm(PropPres~AvgLunIllum,family=gamma,data=masterLun,id=GroupID,corstr="ar1")
# Test whether to include Lunar Illuminance as a linear or a smooth term:
mod01 = geeglm(PropPres~AvgLunIllum,family=poisson,data=masterLun,id=GroupID,corstr="ar1")
View(masterLun)
# Round Proportion of Presence to get it Poisson distributed
masterLun$PropPres = round(masterLun$PropPres*100,digits=0)
# load file
masterLun = data.frame(read.csv(lunList[i]))
plot(masterLun$PropPres[masterLun$PropPres>0])
# Round Proportion of Presence to get it Poisson distributed
masterLun$PropPres = round(masterLun$PropPres*100,digits=0)
plot(masterLun$PropPres[masterLun$PropPres>0])
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
unlist(knots[1])
knots=quantile(thisSite$LunarIllum,probs=unlist(knots[1]))
# knots = list(c(0.333,0.666),c(0.275,0.5,0.725))
knots = list(c(0.5),c(0.333,0.666))
quantile(thisSite$LunarIllum,probs=unlist(knots[1]))
lunList
mod03 = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(thisSite$LunarIllum,probs=unlist(knots[2])),
Boundary.knots=c(0,1)),
family=poisson,data=masterLun,id=GroupID,corstr="ar1")
mod02 = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(masterLun$AvgLunIllum,probs=unlist(knots[1])),
Boundary.knots=c(0,1)),
family=poisson,data=masterLun,id=GroupID,corstr="ar1")
mod03 = geeglm(PropPres~mSpline(AvgLunIllum,
knots=quantile(masterLun$AvgLunIllum,probs=unlist(knots[2])),
Boundary.knots=c(0,1)),
family=poisson,data=masterLun,id=GroupID,corstr="ar1")
QICLunIllum = c(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]])
mod04 = geeglm(PropPres~PropMoonUp,family=poisson,data=masterLun,id=GroupID,corstr="ar1")
mod05 = geeglm(PropPres~mSpline(PropMoonUp,
knots=quantile(masterLun$PropMoonUp,probs=unlist(knots[1])),
Boundary.knots=c(0,1)),
family=poisson,data=masterLun,id=GroupID,corstr="ar1")
mod06 = geeglm(PropPres~mSpline(PropMoonUp,
knots=quantile(masterLun$PropMoonUp,probs=unlist(knots[2])),
Boundary.knots=c(0,1)),
family=poisson,data=masterLun,id=GroupID,corstr="ar1")
QICPropMoonUp = c(QIC(mod04)[[1]],QIC(mod05)[[1]],QIC(mod06)[[1]])
# mod05 = geeglm(Presence~mSpline(JulianDay,
#                                 knots=quantile(thisSite$JulianDay, probs=unlist(knots[2])),
#                                 Boundary.knots=c(1,365),
#                                 periodic=T),
#                family=binomial,data=thisSite,id=GroupID,corstr="ar1")
# QICJD = c(QIC(mod04)[[1]],QIC(mod05)[[1]])
#
#
# numKnots_QIC_Comp[i,] = cbind(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]],
#                      QIC(mod04)[[1]],QIC(mod05)[[1]])
LunKnots_QIC_Comp[i,] = cbind(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]],
QIC(mod04)[[1]],QIC(mod05)[[1]],QIC(mod065)[[1]])
# mod05 = geeglm(Presence~mSpline(JulianDay,
#                                 knots=quantile(thisSite$JulianDay, probs=unlist(knots[2])),
#                                 Boundary.knots=c(1,365),
#                                 periodic=T),
#                family=binomial,data=thisSite,id=GroupID,corstr="ar1")
# QICJD = c(QIC(mod04)[[1]],QIC(mod05)[[1]])
#
#
# numKnots_QIC_Comp[i,] = cbind(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]],
#                      QIC(mod04)[[1]],QIC(mod05)[[1]])
LunKnots_QIC_Comp[i,] = cbind(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]],
QIC(mod04)[[1]],QIC(mod05)[[1]],QIC(mod06)[[1]])
View(LunKnots_QIC_Comp)
LunKnots_QIC_Comp = data.frame(LunIllumLin=as.numeric(),
LunIllum3=as.numeric(),
LunIllum4=as.numeric(),
MoonPropLin=as.numeric(),
MoonProp3=as.numeric(),
MoonProp4=as.numeric())
# mod05 = geeglm(Presence~mSpline(JulianDay,
#                                 knots=quantile(thisSite$JulianDay, probs=unlist(knots[2])),
#                                 Boundary.knots=c(1,365),
#                                 periodic=T),
#                family=binomial,data=thisSite,id=GroupID,corstr="ar1")
# QICJD = c(QIC(mod04)[[1]],QIC(mod05)[[1]])
#
#
# numKnots_QIC_Comp[i,] = cbind(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]],
#                      QIC(mod04)[[1]],QIC(mod05)[[1]])
LunKnots_QIC_Comp[i,] = cbind(QIC(mod01)[[1]],QIC(mod02)[[1]],QIC(mod03)[[1]],
QIC(mod04)[[1]],QIC(mod05)[[1]],QIC(mod06)[[1]])
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
lunList[i]
View(corr)
acf(masterLun$PropPres,lag.max=60,na.action=na.exclude)
# Determine autocorrelation and create grouping variable for GEEGLM
corr = acf(masterLun$PropPres,lag.max=90,na.action=na.exclude,plot=FALSE)
lagID = which(abs(corr$acf)<0.2) # determine lag at which autocorrelation is <0.2
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
View(BestLunIllum)
View(BestMoonPropUp)
lunList
View(LunKnots_QIC_Comp)
BestLunIllum = data.frame(colnames(LunKnots_QIC_Comp)[unlist(data.frame(apply(LunKnots_QIC_Comp[,1:3],1,which.min)))])
colnames(BestLunIllum) = "BestModel"
zed = unlist(data.frame(apply(LunKnots_QIC_Comp[,1:3],1,which.min)))
BestMoonPropUp = data.frame(colnames(LunKnots_QIC_Comp)[(unlist(data.frame(apply(LunKnots_QIC_Comp[,4:5],1,which.min))))+2])
colnames(BestMoonPropUp) = "BestModel"
BestMoonPropUp = data.frame(colnames(LunKnots_QIC_Comp)[(unlist(data.frame(apply(LunKnots_QIC_Comp[,4:5],1,which.min))))+3])
colnames(BestMoonPropUp) = "BestModel"
View(masterLun)
startInd = which(masterLun$NightStart>=as.POSIXct('2017-05-01 00:00:00',format="%Y-%m-%d %H:%M:%S",tz="GMT"))
debugSource("D:/Code/Temporal_Analyses/Temporal_Models.R")
View(masterLun)
